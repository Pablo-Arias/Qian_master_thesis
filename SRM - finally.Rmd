---
title: "SRM"
author: "Qian"
date: "2025-03-18"
output: html_document
---

# Load the tidyverse package below
```{r T101, warning=FALSE, message=FALSE}
# Load the tidyverse package below
cat("\f")
rm(list=ls())

# Init
graphics.off()

#install.packages("ez")
#("phia")
#install.packages("effsize")
#install.packages("srm")
#install.packages("TripleR")
library("MASS")
library(ez)
library(afex)
library(phia)
library(doBy)
library(effsize)
library(lmerTest);
library(dplyr);
library(srm);
library(ggplot2)
library(TripleR)
library(tidyverse)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))


#Import data
file_name = "data/behavior/all_data_df.csv"

#read data
data = read.table(file_name, header=TRUE,sep=',')
head(data)

#defining outcomes
measure			          <-as.numeric(data$measure)

#defining predictors (categorical)
participant_condition 	<- as.factor(data$participant_condition)
participant_condition   <- relevel(participant_condition, "S")
other_condition 		    <- as.factor(data$other_condition)
other_condition         <- relevel(other_condition, "S")
participant_nb			    <- as.factor(data$user_id)
interacting_partner			<- as.factor(data$other_id)
question_content		    <- as.factor(data$question_content)
group_id		            <- as.factor(data$sid)

#create new dataframe
all_data=data.frame( measure, participant_condition , interacting_partner, other_condition, participant_nb, question_content, group_id )

## -------------------------------------- ##
## -------------------------------------- ##
## GLMM Analysis ------------------------ ##
## -------------------------------------- ##
## -------------------------------------- ##

# Choose the question you want to anlayse
#question = "conversation_quality"
#question = "liked"
question = "other_liked"
#question = "video_conf_quality"

clean_data <- all_data[all_data$question_content == question,]
head(clean_data)


#Social relation Model
RR.style("perception")

#Round Robin
RR1 <- RR(measure ~ participant_nb * interacting_partner | group_id, data = clean_data, na.rm = TRUE)
RR1


#Missing values
plot_missings(measure ~ participant_nb * interacting_partner | group_id, data = clean_data, show.ids = FALSE)

#Variance covariance
plot(RR1)


RR1$effects #measure perceiver and target
RR1$effectsRel

result_file = paste("data/behavior/srm/",question,".csv", sep="")
write.csv(RR1$effectsRel, result_file) #Relationships

# 保存 perceiver & target effects
result_file_effects <- paste("data/behavior/srm/", question, "_effects.csv", sep = "")
write.csv(RR1$effects, result_file_effects, row.names = FALSE)

#保存方差
RR1$varComp.groups
result_file_variance <- paste("data/behavior/srm/", question, "_variance.csv", sep = "")
write.csv(RR1$VAR, result_file_variance, row.names = FALSE)

df = data(likingLong)


str(likingLong)

# Load required libraries
library(lme4)
library(ggplot2)

# Function to run GLMM for each SRM dataset
run_srm_glmm <- function(data, title) {
  # Ensure factors are properly set
  data$participant_condition <- as.factor(data$participant_condition)
  data$other_condition <- as.factor(data$other_condition)

  # Run the GLMM
  glmm_model <- lmer(relationship ~ participant_condition * other_condition + 
                      (1 | participant_nb) + (1 | interacting_partner), 
                      data = data)
  
  # Print summary
  print(summary(glmm_model))
  
  # Plot results
  ggplot(data, aes(x = participant_condition, y = relationship, color = other_condition)) +
    geom_point(alpha = 0.3, position = position_jitter(width = 0.2)) +
    stat_summary(fun = mean, geom = "point", size = 4, position = position_dodge(0.2)) +
    stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2, position = position_dodge(0.2)) +
    labs(title = title, x = "Participant Condition", y = "Relationship Rating (SRM)") +
    scale_color_manual(values = c("red", "blue")) +
    theme_minimal()
}


# Load datasets
liked <- read_csv("data/behavior/srm/liked.csv")
other_liked <- read_csv("data/behavior/srm/other_liked.csv")
conversation_quality <- read_csv("data/behavior/srm/conversation_quality.csv")
video_conf_quality <- read_csv("data/behavior/srm/video_conf_quality.csv")


# Run SRM GLMM for each dataset
run_srm_glmm(liked, "Liked (SRM Relationship)")
run_srm_glmm(other_liked, "Other Liked Me (SRM Relationship)")
run_srm_glmm(conversation_quality, "Conversation Quality (SRM Relationship)")
run_srm_glmm(video_conf_quality, "Video Conference Quality (SRM Relationship)")

```
```{r}
#合并数据
# 筛选主表中 question_content 为 liked 的子集

               # ← liked 中含 relationship 值

library(dplyr)
library(readr)

# 1. 读取数据
all_data_df <- read.csv("data/behavior/all_data_df.csv")     # ← 替换为你的路径
liked <- read_csv("data/behavior/srm/liked.csv")                  # ← liked 中含 relationship 值



# 2. 重命名 liked 子表字段以匹配主表
liked_clean <- liked %>%
  rename(
    sid = group.id,
    user_id = participant_nb,
    other_id = interacting_partner
  ) %>%
  mutate(
    sid = as.character(sid),
    user_id = as.character(user_id),
    other_id = as.character(other_id)
  )

# 3. 确保主表字段类型一致
all_data_df <- all_data_df %>%
  mutate(
    sid = as.character(sid),
    user_id = as.character(user_id),
    other_id = as.character(other_id)
  )

# 4. 仅对 liked 条目合并 relationship 分数
all_data_liked <- all_data_df %>%
  filter(question_content == "liked") %>%
  left_join(
    liked_clean[, c("sid", "user_id", "other_id", "relationship")],
    by = c("sid", "user_id", "other_id")
  )

# 5. 非 liked 条目保持原样，relationship 设为 NA
all_data_other <- all_data_df %>%
  filter(question_content != "liked") %>%
  mutate(relationship = NA)

# 6. 合并为完整表
all_data_srm <- bind_rows(all_data_other, all_data_liked)

# 7. 保存结果为新文件
write_csv(all_data_srm, "all_data_srm.csv")


```
```{r}
#合并relationship
#循环遍历读取所有问题的
library(dplyr)
library(readr)

# 1. 读取主表
all_data_df <- read_csv("data/behavior/all_data_df.csv") %>%
  mutate(
    sid = as.character(sid),
    user_id = as.character(user_id),
    other_id = as.character(other_id)
  )

# 2. 设定子表文件所在路径
srm_path <- "data/behavior/srm"
question_list <- c("liked", "other_liked", "conversation_quality", "video_conf_quality")

# 3. 用于存储每一类合并后的数据
merged_chunks <- list()

# 4. 循环读取并合并
for (question in question_list) {
  
  file_path <- file.path(srm_path, paste0(question, ".csv"))
  
  if (file.exists(file_path)) {
    
    srm_df <- read_csv(file_path) %>%
      rename(
        sid = group.id,
        user_id = participant_nb,
        other_id = interacting_partner
      ) %>%
      mutate(
        sid = as.character(sid),
        user_id = as.character(user_id),
        other_id = as.character(other_id)
      )
    
    # 筛选主表中对应 question 的子集并合并
    data_q <- all_data_df %>%
      filter(question_content == question) %>%
      left_join(
        srm_df[, c("sid", "user_id", "other_id", "relationship")],
        by = c("sid", "user_id", "other_id")
      )
    
    merged_chunks[[question]] <- data_q
    
  } else {
    message(paste("⚠️ 文件未找到:", file_path, "- 已跳过该项"))
    
    # 无文件也保留数据并填入 NA
    merged_chunks[[question]] <- all_data_df %>%
      filter(question_content == question) %>%
      mutate(relationship = NA)
  }
}

# 5. 合并所有部分
all_data_srm <- bind_rows(merged_chunks)

# 6. 保存最终数据
write_csv(all_data_srm, "all_data_srm.csv")

message("✅ all_data_srm.csv 已成功保存！")

```
```{r}
#定义function
# Load required libraries
library(lme4)
library(ggplot2)

# Function to run GLMM for each SRM dataset
run_srm_glmm <- function(data, title) {
  # Ensure factors are properly set
  data$participant_condition <- as.factor(data$participant_condition)
  data$other_condition <- as.factor(data$other_condition)

  # Run the GLMM
  glmm_model <- lmer(relationship ~ participant_condition * other_condition + 
                      (1 | participant_nb) + (1 | interacting_partner), 
                      data = data)
  
  # Print summary
  print(summary(glmm_model))
  
  # Plot results
  ggplot(data, aes(x = participant_condition, y = relationship, color = other_condition)) +
    geom_point(alpha = 0.3, position = position_jitter(width = 0.2)) +
    stat_summary(fun = mean, geom = "point", size = 4, position = position_dodge(0.2)) +
    stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2, position = position_dodge(0.2)) +
    labs(title = title, x = "Participant Condition", y = "Relationship Rating (SRM)") +
    scale_color_manual(values = c("red", "blue")) +
    theme_minimal()
}


# Load datasets
liked <- read_csv("data/behavior/srm/liked.csv")
other_liked <- read_csv("data/behavior/srm/other_liked.csv")
conversation_quality <- read_csv("data/behavior/srm/conversation_quality.csv")
video_conf_quality <- read_csv("data/behavior/srm/video_conf_quality.csv")


# Run SRM GLMM for each dataset
run_srm_glmm(liked, "Liked (SRM Relationship)")
run_srm_glmm(other_liked, "Other Liked Me (SRM Relationship)")
run_srm_glmm(conversation_quality, "Conversation Quality (SRM Relationship)")
run_srm_glmm(video_conf_quality, "Video Conference Quality (SRM Relationship)")
```



```{r}
#用老师的方法
#重现图表 用srm模型

library(lme4)
library(ggplot2)

# Function to run GLMM for each SRM dataset
run_srm_glmm <- function(data, title) {
  # Ensure factors are properly set
  data$participant_condition <- as.factor(data$participant_condition)
  data$other_condition <- as.factor(data$other_condition)

  # Run the GLMM
  glmm_model <- lmer(relationship ~ participant_condition * other_condition + 
                      (1 | participant_nb) + (1 | interacting_partner), 
                      data = data)
  
  # Print summary
  print(summary(glmm_model))
  
  # Plot results
  ggplot(data, aes(x = participant_condition, y = relationship, color = other_condition)) +
    geom_point(alpha = 0.3, position = position_jitter(width = 0.2)) +
    stat_summary(fun = mean, geom = "point", size = 4, position = position_dodge(0.2)) +
    stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2, position = position_dodge(0.2)) +
    labs(title = title, x = "Participant Condition", y = "Relationship Rating (SRM)") +
    scale_color_manual(values = c("red", "blue")) +
    theme_minimal()
}



liked <- read_csv("all_data_srm.csv") %>%


# Run SRM GLMM for each dataset
run_srm_glmm(liked, "Liked (SRM Relationship)")

```

```{r}
#2用自己的方法  relationship
#重现图表 用srm模型

# 1. 加载包
library(tidyverse)
library(dplyr)
library(TripleR)
library(lme4)
library(lmerTest)
library(ggplot2)

# 2. 假设数据已读入为 df
df <- read_csv("all_data_srm_unique.csv")



# 修正编码（S = increase smile, U = decrease smile）
df <- df %>%
  mutate(
    participant_condition = recode(participant_condition, "S" = "increase", "U" = "decrease"),
    other_condition = recode(other_condition, "S" = "increase", "U" = "decrease")
  )

# 映射标签
df$question_label <- recode(df$question_content,
  "liked" = "A. Liked",
  "other_liked" = "B. Other liked me",
  "conversation_quality" = "C. Conversation quality",
  "video_conf_quality" = "D. Video conference quality"
)

# 设置因子顺序（保证图表排序和配色一致）
df$participant_condition <- factor(df$participant_condition, levels = c("increase", "decrease"))
df$other_condition <- factor(df$other_condition, levels = c("increase", "decrease"))
df$question_label <- factor(df$question_label,
  levels = c("A. Liked", "B. Other liked me", "C. Conversation quality", "D. Video conference quality"))

# 绘图
g <- ggplot(df, aes(x = participant_condition, y = measure.p, color = other_condition)) +
  geom_jitter(width = 0.15, alpha = 0.2, size = 1.2) +  # 散点图层
  stat_summary(fun = mean, geom = "point", size = 3,
               position = position_dodge(width = 0.4)) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2,
               position = position_dodge(width = 0.4)) +
  stat_summary(fun = mean, geom = "line",
               position = position_dodge(width = 0.4), aes(group = other_condition), size = 0.8) +
  scale_color_manual(values = c("increase" = "red", "decrease" = "blue"),
                     name = "Other condition",
                     labels = c("increase smile", "decrease smile")) +
  facet_wrap(~question_label, nrow = 1) +
  labs(
    x = "Participant condition",
    y = "Participant Rating\n(relationship value in the SRM)",
    title = "Figure 6. Psychological analysis"
  ) +
  theme_minimal(base_size = 12)

# 展示图
print(g)

# 可选：保存为高分辨图像
ggsave("Figure6_final.png", g, width = 13, height = 5, dpi = 300)
```



```{r}
#relationship SRM  计算得到relationship value、measure.p、measure.t并存表
cat("\f")
rm(list=ls())

# Init
graphics.off()

#install.packages("ez")
#("phia")
#install.packages("effsize")
#install.packages("srm")
#install.packages("TripleR")
library("MASS")
library(ez)
library(afex)
library(phia)
library(doBy)
library(effsize)
library(lmerTest);
library(dplyr);
library(srm);
library(ggplot2)
library(TripleR)
library(tidyverse)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))


#Import data
file_name = "all_data_srm.csv"

#read data
data = read.table(file_name, header=TRUE,sep=',')
head(data)

#defining outcomes
measure			          <-as.numeric(data$measure)

#defining predictors (categorical)
participant_condition 	<- as.factor(data$participant_condition)
participant_condition   <- relevel(participant_condition, "S")
other_condition 		    <- as.factor(data$other_condition)
other_condition         <- relevel(other_condition, "S")
participant_nb			    <- as.factor(data$user_id)
interacting_partner			<- as.factor(data$other_id)
question_content		    <- as.factor(data$question_content)
group_id		            <- as.factor(data$sid)

#create new dataframe
all_data=data.frame( measure, participant_condition , interacting_partner, other_condition, participant_nb, question_content, group_id )

## -------------------------------------- ##
## -------------------------------------- ##
## GLMM Analysis ------------------------ ##
## -------------------------------------- ##
## -------------------------------------- ##

# Choose the question you want to anlayse
#question = "conversation_quality"
#question = "liked"
#question = "other_liked"
#question = "video_conf_quality"

clean_data <- all_data[all_data$question_content == question,]
head(clean_data)


#Social relation Model
RR.style("perception")

#Round Robin
RR1 <- RR(measure ~ participant_nb * interacting_partner | group_id, data = clean_data, na.rm = TRUE)
RR1


#Missing values
plot_missings(measure ~ participant_nb * interacting_partner | group_id, data = clean_data, show.ids = FALSE)

#Variance covariance
plot(RR1)


RR1$effects #measure perceiver and target
RR1$effectsRel

result_file = paste("data/behavior/srm/",question,".csv", sep="")
#write.csv(RR1$effectsRel, result_file) #Relationships

# 保存 perceiver & target effects
result_file_effects <- paste("data/behavior/srm/", question, "_effects.csv", sep = "")
#write.csv(RR1$effects, result_file_effects, row.names = FALSE)

df = data(likingLong)


str(likingLong)
```



```{r}
#遍历处理合并数据measure.p和measure.t  条件 sid = group.id, user_id = id
library(dplyr)
library(readr)



# 1. 读取主表
all_data_df <- read_csv("all_data_srm.csv") %>%
  mutate(
    sid = as.character(sid),
    user_id=as.character(user_id)  )

# 2. 设定子表文件所在路径
srm_path <- "data/behavior/srm"
question_list <- c("liked", "other_liked", "conversation_quality", "video_conf_quality")

# 3. 用于存储每一类合并后的数据
merged_chunks <- list()

# 4. 循环读取并合并
for (question in question_list) {
  
  file_path <- file.path(srm_path, paste0(question, "_effects.csv"))
  
  if (file.exists(file_path)) {
    
    srm_df <- read_csv(file_path) %>%
      rename(
        sid = group.id,
        user_id = id
      ) %>%
      mutate(
        sid = as.character(sid),
        user_id = as.character(user_id)
      )
    
    # 筛选主表中对应 question 的子集并合并
    data_q <- all_data_df %>%
      filter(question_content == question) %>%
      left_join(
        srm_df[, c("sid", "user_id", "measure.p", "measure.t")],
        by = c("sid", "user_id")
      )
    
    merged_chunks[[question]] <- data_q
    
  } else {
    message(paste("⚠️ 文件未找到:", file_path, "- 已跳过该项"))
    
    # 无文件也保留数据并填入 NA
    merged_chunks[[question]] <- all_data_df %>%
      filter(question_content == question) %>%
      mutate(relationship = NA)
  }
}

# 5. 合并所有部分
all_data_srm <- bind_rows(merged_chunks)

# 6. 保存最终数据
write_csv(all_data_srm, "all_data_srm_all.csv")
message("🎉 所有可用效应已成功合并到 all_data_srm_all.csv")




```

```{r}
#去重
library(dplyr)
library(readr)

# 读取数据
df <- read_csv("all_data_srm_all.csv")

# 按 sid 和 user_id 分组，保留第一条记录（因 perceiver/target_effect 相同）
df_unique <- df %>%
  group_by(sid, user_id , question_content) %>%
  slice(1) %>%
  ungroup()

# 保存去重结果（可选）
write_csv(df_unique, "all_data_srm_unique.csv")

message("✅ 已完成按 sid + user_id 去重并保留唯一行。")

```


```{r}
#画图
# 加载必要包
library(ggplot2)
library(dplyr)

# 读取数据（假设你已经用 read.csv() 读入为 df）
df <- read.csv("all_data_srm_unique.csv")


ggplot(df, aes(x = question_content, y = measure.t)) +
  geom_boxplot(fill = "lightblue", alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.4, color = "black") +
  theme_minimal() +
  labs(title = "measure.p by Question Content",
       x = "Question Content",
       y = "pe")

```


```{r}
#小提琴图
# 加载必要的包
library(ggplot2)

# 读取数据（假设你已将数据读入为 df）
df <- read.csv("all_data_srm_unique.csv")

# 绘制箱线图
df %>% 
  drop_na(question_content) %>% 
  mutate(question_content = factor(question_content, 
                         levels = c("liked", "other_liked","conversation_quality","video_conf_quality"))) %>% 
  ggplot(aes(y = measure.p, x = question_content, fill = question_content)) +
  geom_boxplot() + 
  scale_y_continuous(name = "Interest score (1-7)", 
                     breaks = c(1:7)) + 
  scale_fill_viridis_d(option = "E", 
                       alpha = 0.6) + 
  guides(fill = "none")


```

```{r}
#柱状图

# 读取数据（假设你已将数据读入为 df）
df <- read.csv("all_data_srm_unique.csv")
# 加载必要包
library(ggplot2)
library(dplyr)



# 假设你的数据框名为 df
# 1. 计算每个 question_content 的平均值
mean_df <- df %>%
  group_by(question_content) %>%
  summarise(mean_measure_p = mean(measure.t, na.rm = TRUE))

View(mean_df)

ggplot(mean_df, aes(x = question_content, y = mean_measure_p)) +
  geom_col(fill = "skyblue") +
  geom_text(aes(label = signif(mean_measure_p, 3)), vjust = -0.5) +
  theme_minimal() +
  labs(title = "Mean of measure.p by Question Content",
       x = "Question Content",
       y = "Mean of measure.p") +
  coord_cartesian(ylim = c(-0.01, 0.01)) +  # 手动设置y轴范围
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



```


```{r}
#correlation  重现原始数据实验 

# 1. 加载包
library(tidyverse)
library(dplyr)
library(TripleR)
library(lme4)
library(lmerTest)
library(ggplot2)
library(correlation)

# 2. 假设数据已读入为 df
df <- read_csv("../Dissertation/all_data_df.csv")


# 修正编码（S = decrease smile, U = increase smile）
df <- df %>%
  mutate(
    question1 = recode(align_condition, "S" = "aligned", "U" = "misaligned"),
    other_condition = recode(other_condition, "S" = "decrease", "U" = "increase")
  )

# 映射标签
df$question_label <- recode(df$question_content,
  "liked" = "A. Liked",
  "other_liked" = "B. Other liked me",
 
)

# 设置因子顺序（保证图表排序和配色一致）
df$question1 <- factor(df$question1, levels = c("increase", "decrease"))
df$other_condition <- factor(df$other_condition, levels = c("increase", "decrease"))
df$question_label <- factor(df$question_label,
  levels = c("A. Liked", "B. Other liked me", "C. Conversation quality", "D. Video conference quality"))

# 绘图
g <- ggplot(df, aes(x = question1, y = measure, color = other_condition)) +
  geom_jitter(width = 0.15, alpha = 0.2, size = 1.2) +  # 散点图层
  stat_summary(fun = mean, geom = "point", size = 3,
               position = position_dodge(width = 0.4)) +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.2,
               position = position_dodge(width = 0.4)) +
  stat_summary(fun = mean, geom = "line",
               position = position_dodge(width = 0.4), aes(group = other_condition), size = 0.8) +
  scale_color_manual(values = c("increase" = "red", "decrease" = "blue"),
                     name = "Other condition",
                     labels = c("increase smile", "decrease smile")) +
  facet_wrap(~question_label, nrow = 1) +
  labs(
    x = "Participant condition",
    y = "Participant Rating\n(relationship value in the SRM)",
    title = "Figure 6. Psychological analysis"
  ) +
  theme_minimal(base_size = 12)

# 展示图
print(g)
```

```{r}
# correlation  between measure.p and measure.t

#install.packages("correlation")  # 如果还没装

#查看总的correlation
library(correlation)

df <- read_csv("all_data_srm_all.csv")
df %>% 
  ggplot(aes(x = measure.p, y = measure.t)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "measure.p", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " measure.t", 
                     breaks = c(1:6))

correlation(data = df, 
            select = "measure.p", 
            select2 = "measure.t",  
            method = "spearman",
            alternative = "two.sided")


#按照问题分组
library(purrr)

# 1. 按 question_content 分组
grouped <- df %>%
  group_by(question_content) %>%
  group_split()

# 2. 对每一组运行 correlation()
cor_list <- map(grouped, ~ correlation(select(., measure.p, measure.t), method = "spearman"))

# 3. 加上分组名并组合成一个表
names(cor_list) <- sapply(grouped, function(x) unique(x$question_content))
cor_combined <- bind_rows(cor_list, .id = "question_content")

# 查看
print(cor_combined)



#读取原始数据 分析相关性

originaldata <- read_csv("data/behavior/srm/liked_effects.csv")


correlation(data = originaldata, 
            select = "measure.p", 
            select2 = "measure.t",  
            method = "spearman",
            alternative = "two.sided")

```

```{r}
# 看relationship的分布
#画图
# 加载必要包
library(ggplot2)
library(dplyr)

# 读取数据（假设你已经用 read.csv() 读入为 df）
df <- read.csv("all_data_srm_all.csv")


ggplot(df, aes(x = question_content, y = relationship)) +
  geom_boxplot(fill = "lightblue", alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.4, color = "black") +
  theme_minimal() +
  labs(title = "relationship by Question Content",
       x = "Question Content",
       y = "relationship")


```

```{r}
#calculate correlation
library(dplyr)
library(tidyr)

# 假设你的数据叫 df，且已加载
df <- read.csv("all_data_srm_all.csv")  # 替换为你的实际路径

# 创建标准 dyad（双向统一）
df <- df %>%
  mutate(dyad_std = ifelse(as.character(user_id) < as.character(other_id),
                           paste(user_id, other_id, sep = "_"),
                           paste(other_id, user_id, sep = "_")))

# 只保留 measure（或 relationship）两个方向都存在的数据
df_wide <- df %>%
  select(dyad_std, user_id, other_id, question_content, measure) %>%
  pivot_wider(names_from = user_id, values_from = measure)  # 宽格式转化

# 或者另一种做法：配对并合并成 A→B 和 B→A 两行拼一行
df_paired <- df %>%
  select(dyad_std, question_content, user_id, other_id, measure) %>%
  group_by(dyad_std, question_content) %>%
  filter(n() == 2) %>%
  arrange(dyad_std, question_content, user_id) %>%
  mutate(pair_id = paste0(dyad_std, "_", question_content)) %>%
  summarise(
    rel1 = first(measure),
    rel2 = last(measure)
  )

# 计算配对相关性（每种 question_content 一次）
cor_results <- df_paired %>%
  group_by(question_content) %>%
  summarise(
    correlation = cor(rel1, rel2, use = "complete.obs"),
    n = n()
  )

print(cor_results)

ggplot(df_paired, aes(x = rel1, y = rel2)) +
  geom_point(alpha = 0.6, color = "orange") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Reciprocal Relationship Scores: A→B vs B→A",
       x = "A to B (relationship score)",
       y = "B to A (relationship score)") +
  theme_minimal()


library(ggplot2)

ggplot(df_paired, aes(x = rel1, y = rel2)) +
  geom_point(alpha = 0.6, color = "orange") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  facet_wrap(~ question_content) +  # 按问题类型分面
  labs(
    title = "Reciprocal Relationship Scores by Question Content",
    x = "A to B (relationship score)",
    y = "B to A (relationship score)"
  ) +
  theme_minimal()

#install.packages("ggpubr")  # 只需一次
library(ggpubr)


ggplot(df_paired, aes(x = rel1, y = rel2)) +
  geom_point(alpha = 0.6, color = "orange") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  stat_cor(method = "spearman", label.x = -2.5, label.y = 2.5) +  # 添加相关系数
  facet_wrap(~ question_content) +
  labs(
    title = "Reciprocal Relationship (Spearman r) by Question Content",
    x = "A to B (relationship score)",
    y = "B to A (relationship score)"
  ) +
  theme_minimal()

library(correlation)
df_paired %>% 
  ggplot(aes(x = measure.p, y = measure.t)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "measure.p", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " measure.t", 
                     breaks = c(1:6))

correlation(data = df, 
            select = "measure.p", 
            select2 = "measure.t",  
            method = "spearman",
            alternative = "two.sided")


```

```{r}
#correlation  同一组AtoB 和Bto A  同一个问题的correlation
#calculate correlation
library(dplyr)
library(tidyr)
library(tidyverse)
library(dplyr)
library(TripleR)
library(lme4)
library(lmerTest)
library(ggplot2)
library(correlation)

# 假设你的数据叫 df，且已加载
df <- read.csv("all_data_srm_all.csv")  # 替换为你的实际路径

# 创建标准 dyad（双向统一）
df <- df %>%
  mutate(dyad_std = ifelse(as.character(user_id) < as.character(other_id),
                           paste(user_id, other_id, sep = "_"),
                           paste(other_id, user_id, sep = "_")))

# 只保留 measure（或 relationship）两个方向都存在的数据
df_wide <- df %>%
  select(dyad_std, user_id, other_id, question_content, measure,relationship) %>%
  pivot_wider(names_from = user_id, values_from = measure)  # 宽格式转化

# 或者另一种做法：配对并合并成 A→B 和 B→A 两行拼一行
df_paired <- df %>%
  select(dyad_std, question_content, user_id, other_id, measure,relationship) %>%
  group_by(dyad_std, question_content) %>%
  filter(n() == 2) %>%
  arrange(dyad_std, question_content, user_id) %>%
  mutate(pair_id = paste0(dyad_std, "_", question_content)) %>%
  summarise(question_content,
    rel1 = first(measure),
    rel2 = last(measure),
    relationship1=first(relationship),
    relationship2=last(relationship)
  )

df_paired %>% 
  ggplot(aes(x = rel1, y = rel2)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "rel1", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " rel2", 
                     breaks = c(1:6))

#存表
#write.csv(df_paired, "data/behavior/srm/correlation.csv", row.names = FALSE)



correlation(data = df_paired, 
            select = "rel1", 
            select2 = "rel2",  
            method = "spearman",
            alternative = "two.sided")


library(correlation)

# 只取你要分析的列，构建一个简洁数据框
rel_data  <- df_paired %>% select(rel1, rel2)

# 使用 correlation() 明确说明列名，不让它自动分组
cor_result <- correlation(
  data = rel_data,
  method = "spearman"
)
print(cor_result)

library(purrr)

# 1. 按 question_content 分组
grouped <- df_paired %>%
  group_by(question_content) %>%
  group_split()

# 2. 对每一组运行 correlation()
cor_list <- map(grouped, ~ correlation(select(., rel1, rel2), method = "spearman"))

# 3. 加上分组名并组合成一个表
names(cor_list) <- sapply(grouped, function(x) unique(x$question_content))
cor_combined <- bind_rows(cor_list, .id = "question_content")

# 查看
print(cor_combined)


# 查看结果
print(cor_result)


# 计算配对相关性（每种 question_content 一次）
cor_results <- df_paired %>%
  group_by(question_content) %>%
  summarise(
    correlation = cor(rel1, rel2, use = "complete.obs"),
    n = n()
  )

print(cor_results)


```

```{r}
#计算关系 同一组AtoB 和Bto A  同一个dyad之间对同一个问题的评分之间的联系
library(ggplot2)
library(correlation)
library(dplyr)

df <- read.csv("data/behavior/srm/correlation.csv")  # 替换为你的实际路径

df %>% 
  ggplot(aes(x = rel1, y = rel2)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "rel1", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " rel2", 
                     breaks = c(1:6))

correlation(data = df, 
            select = "rel1", 
            select2 = "rel2",  
            method = "spearman",
            alternative = "two.sided")


library(purrr)

#去重
df_unique <- df %>%
  distinct(dyad_std, question_content, .keep_all = TRUE)

# 1. 按 question_content 分组



grouped <- df_unique %>%
  group_by(question_content) %>%
  group_split()

# 2. 对每一组运行 correlation()
cor_list <- map(grouped, ~ correlation(select(., rel1, rel2), method = "spearman"))

# 3. 加上分组名并组合成一个表
names(cor_list) <- sapply(grouped, function(x) unique(x$question_content))
cor_combined <- bind_rows(cor_list, .id = "question_content")

# 查看
print(cor_combined)

df_liked <- df %>% 
  filter(question_content == "liked")

df_liked %>% 
  ggplot(aes(x = rel1, y = rel2)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "rel1", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " rel2", 
                     breaks = c(1:6))

correlation(data = df_liked, 
            select = "rel1", 
            select2 = "rel2",  
            method = "spearman",
            alternative = "two.sided")

```

```{r}
#计算liked和other_liked之间的correlation  --数据清洗
library(dplyr)
library(tidyr)

library(correlation)

df <- read.csv("data/behavior/all_data_df.csv")  # 替换为你的实际路径

# 1. 筛选 liked 和 other_liked
df_filtered <- df %>%
  filter(question_content %in% c("liked", "other_liked"))

# 2. 按 dyad + 参与者信息分组，并宽格式转化
df_wide <- df_filtered %>%
  group_by(dyad, user_id, other_id, participant_condition, other_condition) %>%
  filter(n() == 2) %>%  # 确保 liked 和 other_liked 都存在
  select(dyad, user_id, other_id, participant_condition, other_condition,
         question_content, measure) %>%
  pivot_wider(names_from = question_content, values_from = measure) %>%
  drop_na(liked, other_liked)  # 防止有缺失

#存表
write.csv(df_wide, "data/behavior/srm/correlation_liked_otherliked.csv", row.names = FALSE)




```

```{r}
#correlation  between liked and other_liked
library(ggplot2)
library(correlation)
library(dplyr)

df <- read.csv("data/behavior/srm/correlation_liked_otherliked.csv")  # 替换为你的实际路径


df %>% 
  ggplot(aes(x = liked, y = other_liked)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "liked", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " other_liked", 
                     breaks = c(1:6))

correlation(data = df, 
            select = "liked", 
            select2 = "other_liked",  
            method = "spearman",
            alternative = "two.sided")


library(pwr)

# Spearman 相关系数
rho <- 0.87

# 计算最小样本量
result <- pwr.r.test(r = rho,
                     sig.level = 0.05,
                     power = 0.80,
                     alternative = "two.sided")

# 输出结果
print(result)


```

```{r}
#计算condition相同下的同样问题A2B 和B2A的相关性--数据清洗部分


library(dplyr)
library(tidyr)

# 假设你的原始数据叫 df
df <- read.csv("data/behavior/all_data_df.csv")  # 替换为你的实际路径

# 第一步：为每组构建唯一标识（方便 group_by）
# 创建标准 dyad（双向统一）
df <- df %>%
  mutate(dyad_std = ifelse(as.character(user_id) < as.character(other_id),
                           paste(user_id, other_id, sep = "_"),
                           paste(other_id, user_id, sep = "_")))

# 只保留 measure（或 relationship）两个方向都存在的数据
df_wide <- df %>%
  select(dyad_std, user_id, other_id, question_content, measure) %>%
  pivot_wider(names_from = user_id, values_from = measure)  # 宽格式转化

# 或者另一种做法：配对并合并成 A→B 和 B→A 两行拼一行
df_paired <- df %>%
  select(dyad_std, question_content, user_id, other_id, measure, participant_condition,other_condition) %>%
  group_by(dyad_std, question_content,participant_condition,other_condition) %>%
  filter(n() == 2) %>%
  arrange(dyad_std, question_content, user_id) %>%
  mutate(pair_id = paste0(dyad_std, "_", question_content)) %>%
  summarise(question_content,
    rel1 = first(measure),
    rel2 = last(measure)
  )

#存表
write.csv(df_paired, "data/behavior/srm/correlation_samecondition.csv", row.names = FALSE)

```

```{r}
#计算condition相同下的同样问题A2B 和B2A的相关

library(purrr)
library(dplyr)

df <- read.csv("data/behavior/srm/correlation_samecondition.csv")  # 替换为你的实际路径

#去重
df_unique <- df %>%
  distinct(dyad_std, question_content, .keep_all = TRUE)

# 1. 按 question_content 分组



grouped <- df %>%
  group_by(question_content) %>%
  group_split()

# 2. 对每一组运行 correlation()
cor_list <- map(grouped, ~ correlation(select(., rel1, rel2), method = "spearman"))

print(cor_list)
```


```{r}
#分析 1：own_other_liked vs. partner_liked（我能否预测别人喜欢我）

#分析 2：partner_other_liked vs. own_liked（别人能否预测我喜欢他）

# 读取数据
data <- read.csv("data/behavior/all_data_df.csv")  # 请替换成你的 CSV 路径

# 仅保留 liked 和 other_liked 两类问题
filtered_data <- subset(data, question_content %in% c("liked", "other_liked"))

# 将数据 pivot_wider，方便后续匹配
library(tidyr)
library(dplyr)

# 把 question_content 的值变成列
wide_data <- filtered_data %>%
  select(dyad, user_id, question_content, measure) %>%
  pivot_wider(names_from = question_content, values_from = measure)

# 将 dyad 内的 user_id 和 other_id 匹配起来
# 也就是说，把 dyad 内的两个人的数据拼在一行

# 分别提取两个人的数据
person1 <- wide_data %>%
  group_by(dyad) %>%
  slice(1) %>%
  rename(user1 = user_id, user1_liked = liked, user1_other_liked = other_liked)

person2 <- wide_data %>%
  group_by(dyad) %>%
  slice(2) %>%
  rename(user2 = user_id, user2_liked = liked, user2_other_liked = other_liked)

# 合并为 dyad 层级
dyad_data <- left_join(person1, person2, by = "dyad")

# 分析 1：我预测别人是否喜欢我
cor_test1 <- cor.test(dyad_data$user1_other_liked, dyad_data$user2_liked)  # user1 猜测 user2 实际
cor_test2 <- cor.test(dyad_data$user2_other_liked, dyad_data$user1_liked)  # user2 猜测 user1 实际

# 分析 2：别人预测我是否喜欢他们
cor_test3 <- cor.test(dyad_data$user2_other_liked, dyad_data$user2_liked)  # user2 猜测 user1 实际
cor_test4 <- cor.test(dyad_data$user1_other_liked, dyad_data$user1_liked)  # user1 猜测 user2 实际

# 查看结果
print(cor_test1)  # user1 的预测准确性
print(cor_test2)  # user2 的预测准确性

# 检查是否存在低估/高估偏差
mean_diff1 <- dyad_data$user1_other_liked - dyad_data$user2_liked
mean_diff2 <- dyad_data$user2_other_liked - dyad_data$user1_liked
t.test(mean_diff1)
t.test(mean_diff2)

```




```{r}
# 能否预测最终版本  这两个相关性应该是一样的吧 因为仅仅是交换纵坐标和横坐标
library(tidyverse)

# 读取数据
data <- read.csv("data/behavior/all_data_df.csv")  # 替换为你的文件路径

# 筛选 liked 和 other_liked 两种题目
filtered_data <- data %>%
  filter(question_content %in% c("liked", "other_liked"))

# 将自己的 liked / other_liked 分别 pivot 为宽格式
own_wide <- filtered_data %>%
  select(dyad, user_id, other_id, question_content, measure) %>%
  pivot_wider(names_from = question_content, values_from = measure) %>%
  rename(own_liked = liked, own_other_liked = other_liked)


# partner 的 liked 和 other_liked，交换 user_id 和 other_id
partner_wide <- filtered_data %>%
  select(dyad, user_id, other_id, question_content, measure) %>%
  pivot_wider(names_from = question_content, values_from = measure) %>%
  rename(partner_liked = liked, partner_other_liked = other_liked) %>%
  rename(user_id_partner = user_id, other_id_partner = other_id)

# 合并：按 dyad 和 user_id / other_id 匹配 partner 数据
merged_data <- own_wide %>%
  left_join(partner_wide,
            by = c("dyad" = "dyad", "user_id" = "other_id_partner", "other_id" = "user_id_partner"))

# 我是否能预测别人喜欢我
cor1 <- cor.test(merged_data$own_other_liked, merged_data$partner_liked, use = "complete.obs")
print(cor1)

# 别人是否能预测我喜欢他们
cor2 <- cor.test(merged_data$partner_other_liked, merged_data$own_liked, use = "complete.obs")
print(cor2)

cor.test(merged_data$partner_other_liked, merged_data$own_liked,
         method = "spearman", use = "complete.obs")

cor.test(merged_data$partner_liked, merged_data$own_other_liked,
         method = "spearman", use = "complete.obs")

write_csv(merged_data, "all_data_dyad_prediction.csv")


merged_data %>% 
  ggplot(aes(x = own_liked, y = partner_other_liked)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "own_liked", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " partner_other_liked", 
                     breaks = c(1:6))

library(correlation)

correlation(data = merged_data, 
            select = "own_liked", 
            select2 = "partner_other_liked",  
            method = "spearman",
            alternative = "two.sided")

correlation(data = merged_data, 
            select = "own_other_liked", 
            select2 = "partner_liked",  
            method = "spearman",
            alternative = "two.sided")
```


```{r}
#筛选出都是增强状态下的微笑 查看是否可以预测
# 读取数据
data <- read.csv("data/behavior/all_data_df.csv")  # 替换为你的文件路径

# 筛选 liked 和 other_liked 两种题目
filtered_data <- data %>%
  filter(question_content %in% c("liked", "other_liked")) %>%
  filter(participant_condition == other_condition)

# 将自己的 liked / other_liked 分别 pivot 为宽格式
own_wide <- filtered_data %>%
  select(dyad, user_id, other_id, question_content, measure) %>%
  pivot_wider(names_from = question_content, values_from = measure) %>%
  rename(own_liked = liked, own_other_liked = other_liked)


# partner 的 liked 和 other_liked，交换 user_id 和 other_id
partner_wide <- filtered_data %>%
  select(dyad, user_id, other_id, question_content, measure) %>%
  pivot_wider(names_from = question_content, values_from = measure) %>%
  rename(partner_liked = liked, partner_other_liked = other_liked) %>%
  rename(user_id_partner = user_id, other_id_partner = other_id)

# 合并：按 dyad 和 user_id / other_id 匹配 partner 数据
merged_data <- own_wide %>%
  left_join(partner_wide,
            by = c("dyad" = "dyad", "user_id" = "other_id_partner", "other_id" = "user_id_partner"))

# 我是否能预测别人喜欢我
cor1 <- cor.test(merged_data$own_other_liked, merged_data$partner_liked, use = "complete.obs")
print(cor1)

# 别人是否能预测我喜欢他们
cor2 <- cor.test(merged_data$partner_other_liked, merged_data$own_liked, use = "complete.obs")
print(cor2)

cor.test(merged_data$partner_other_liked, merged_data$own_liked,
         method = "spearman", use = "complete.obs")


merged_data %>% 
  ggplot(aes(x = own_liked, y = partner_other_liked)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "own_liked", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " partner_other_liked", 
                     breaks = c(1:6))

correlation(data = merged_data, 
            select = "own_liked", 
            select2 = "partner_other_liked",  
            method = "spearman",
            alternative = "two.sided")
```


```{r}
#查看一对之间的relationship的相关性  是否有意义？操纵过的 这个relationship是怎么计算出来的
library(dplyr)
library(tidyr)

# 读取数据
df <- read.csv("your_file.csv")  # 请修改为你的文件路径

# 创建一个 key 用于唯一确定 dyad 关系 (user 对 other) 和 (other 对 user)
df <- df %>%
  mutate(pair = paste(pmin(user_id, other_id), pmax(user_id, other_id), sep = "_"))

# 按 sid、dyad、participant、other_conc、question_c、pair 分组，整理成 wide 格式
df_wide <- df %>%
  select(sid, dyad, participant_condition = participant, other_condition = other_conc, question_content = question_c,
         user_id, other_id, relationship, pair) %>%
  pivot_wider(names_from = user_id, values_from = relationship, values_fn = list(relationship = mean))

# 或者直接 inner_join 方式配对
# 将原始数据复制为两份，一份是 A -> B，一份是 B -> A，进行合并
df_a <- df %>%
  select(sid, dyad, participant_condition = participant, other_condition = other_conc, question_content = question_c,
         user_id_A = user_id, other_id_A = other_id, relationship_A = relationship)

df_b <- df %>%
  select(sid, dyad, participant_condition = participant, other_condition = other_conc, question_content = question_c,
         user_id_B = other_id, other_id_B = user_id, relationship_B = relationship)

# 内连接，将 A->B 和 B->A 的数据配对
paired_df <- inner_join(df_a, df_b,
                        by = c("sid", "dyad", "participant_condition", "other_condition", "question_content",
                               "user_id_A" = "user_id_B", "other_id_A" = "other_id_B"))

# 计算每组的 correlation
result <- paired_df %>%
  group_by(sid, dyad, participant_condition, other_condition, question_content) %>%
  summarise(correlation = cor(relationship_A, relationship_B, use = "complete.obs"),
            .groups = "drop")

# 查看结果
print(result)


```


```{r}
#计算relationship之间的correlation  --数据清洗


# 假设你的数据叫 df，且已加载
df <- read.csv("all_data_srm_all.csv")  # 替换为你的实际路径

# 创建标准 dyad（双向统一）
df <- df %>%
  mutate(dyad_std = ifelse(as.character(user_id) < as.character(other_id),
                           paste(user_id, other_id, sep = "_"),
                           paste(other_id, user_id, sep = "_")))

# 只保留 measure（或 relationship）两个方向都存在的数据
df_wide <- df %>%
  select(dyad_std, user_id, other_id, question_content, relationship) %>%
  pivot_wider(names_from = user_id, values_from = relationship)  # 宽格式转化

# 或者另一种做法：配对并合并成 A→B 和 B→A 两行拼一行
df_paired <- df %>%
  select(dyad_std, question_content, user_id, other_id, relationship) %>%
  group_by(dyad_std, question_content) %>%
  filter(n() == 2) %>%
  arrange(dyad_std, question_content, user_id) %>%
  mutate(pair_id = paste0(dyad_std, "_", question_content)) %>%
  summarise(
    relationship1 = first(relationship),
    relationship2 = last(relationship)
  )


#存表
write.csv(df_paired, "data/behavior/srm/correlation_relationship.csv", row.names = FALSE)

```
```{r}
# correlation  between relationship

#install.packages("correlation")  # 如果还没装
library(correlation)

df <- read_csv("data/behavior/srm/correlation_relationship.csv")
df %>% 
  ggplot(aes(x = relationship1, y = relationship2)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "measure.p", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " measure.t", 
                     breaks = c(1:6))

correlation(data = df, 
            select = "relationship1", 
            select2 = "relationship2",  
            method = "spearman",
            alternative = "two.sided")


library(purrr)

# 1. 按 question_content 分组
grouped <- df %>%
  group_by(question_content) %>%
  group_split()

# 2. 对每一组运行 correlation()
cor_list <- map(grouped, ~ correlation(select(., relationship1, relationship2), method = "spearman"))

# 3. 加上分组名并组合成一个表
names(cor_list) <- sapply(grouped, function(x) unique(x$question_content))
cor_combined <- bind_rows(cor_list, .id = "question_content")

# 查看
print(cor_combined)


# 查看结果
print(cor_result)



```


```{r}
#AVONA 数据处理以及解析
# 读取数据
data <- read.csv("data/behavior/all_data_df.csv")  # 替换为你的文件路径

# 新增列 alignment
data$alignment <- ifelse(data$participant_condition == data$other_condition, 1, 0)
#存表
write.csv(data, "data/behavior/all_data_df_judge.csv", row.names = FALSE)

data_judge <- read.csv("data/behavior/all_data_df_judge.csv")  # 替换为你的文件路径

# 安装必要包（如未安装请先运行）
# install.packages(c("afex", "tidyverse"))

library(afex)
library(tidyverse)

# 假设您已经读取数据为 data
# data <- read.csv("your_file.csv")

# 将 participant ID 列命名为 id，这里是 sid
# 确保 question_content 和 alignment 都是 factor
data_judge <- data_judge %>%
  mutate(
    alignment = factor(alignment, levels = c(0, 1), labels = c("NotAligned", "Aligned")),
    question_content = factor(question_content),
    sid = as.factor(sid)  # participant identifier
  )

# 执行混合设计 ANOVA
anova_result <- aov_ez(
  id = "sid",                  # 受试者 ID
  dv = "measure",              # 因变量
  data = data,                 # 数据
  within = "question_content", # 被试内变量
  between = "alignment"        # 被试间变量
)

# 查看结果
print(anova_result)

```

```{r}
#分组 对mearurep和mearure.t 计算ANOVA 并保存新的表

# 读取数据
df <- read.csv("all_data_srm_unique.csv")  # 替换为你的文件路径



library(dplyr)
library(tidyr)

# 假设 df 是你的原始数据
df_long <- df %>%
  pivot_longer(
    cols = c(measure.p, measure.t),
    names_to = "condition",
    values_to = "value"
  ) %>%
  mutate(
    condition = recode(condition,
                       "measure.p" = "perceiver_value",
                       "measure.t" = "target_value")
  )

#存表
write.csv(df_long, "all_data_srm_unique_group.csv", row.names = FALSE)

```


```{r}
# 方差 用书上的方式计算

#install.packages("rcompanion")
#install.packages("effectsize")
#install.packages("car")
#install.packages("broom")
#install.packages("emmeans")
#install.packages("performance")
#install.packages("afex")
#install.packages("ez")
library(rcompanion)
library(effectsize)
library(car)
library(broom)
library(broom)
library(emmeans)
library(tidyverse)
library(performance)
library(ez)
library(afex)
# specify as an object, so we only change it in one place
dodge_value  <- read.csv("all_data_srm_unique_group.csv")  # 替换为你的文件路径

dodge_value %>% 
  mutate(value = case_match(condition,
                           "measure.p" ~ "perceiver_value",
                           "measure.t" ~ "target_value")) %>% 
  ggplot(aes(y = value, x = question_content, fill = condition)) +
  geom_violin(alpha = 0.5) + 
  geom_boxplot(width = 0.2, 
               alpha = 0.7,
               fatten = NULL,
               position = position_dodge(dodge_value)) + 
  stat_summary(fun = "mean", 
               geom = "point",
               position = position_dodge(dodge_value)) +
  stat_summary(fun.data = "mean_cl_boot", 
               geom = "errorbar", 
               width = .1,
               position = position_dodge(dodge_value)) +
  scale_fill_viridis_d(option = "E") + 
  scale_y_continuous(name = "Interest score (1-7)", 
                     breaks = c(1:7)) + 
  theme_classic()


#GPT给的代码  可视化
library(dplyr)
library(ggplot2)
library(viridis)
position = position_dodge(width = 0.8)

dodge_value <- read.csv("all_data_srm_unique_group.csv")

dodge_value %>%
  ggplot(aes(y = value, x = question_content, fill = condition)) +
  geom_violin(alpha = 0.5, position = position_dodge(width = 0.8)) +
  geom_boxplot(width = 0.2,
               alpha = 0.7,
               position = position_dodge(width = 0.8)) +
  stat_summary(fun = "mean",
               geom = "point",
               position = position_dodge(width = 0.8)) +
  stat_summary(fun.data = "mean_cl_boot",
               geom = "errorbar",
               width = .1,
               position = position_dodge(width = 0.8)) +
  scale_fill_viridis_d(option = "E") +
  scale_y_continuous(name = "Interest score (1-7)",
                     breaks = c(1:7)) +
  theme_classic()

#计算ANOVA
mod_factorial <- aov_ez(id = "user_id",
                        data = dodge_value, 
                        within = c("condition", "question_content"),
                        dv = "value", 
                        type = 3,
                        include_aov = TRUE,
                        anova_table = list(es = "pes"),
                        na.rm = TRUE) 

factorial_output <- mod_factorial$anova_table %>% 
  tidy()

mod_factorial

```
```{r}
#计算是否微笑  数据治理

# 读取数据
df <- read.csv("data/behavior/all_data_df.csv")  # 替换为你的文件路径



dodge_value <- df %>%
  mutate(condition = paste0(participant_condition, other_condition))


#存表
write.csv(dodge_value, "all_data_condition.csv", row.names = FALSE)

```

```{r}
#计算是否微笑 相关性

dodge_value  <- read.csv("all_data_condition.csv")  # 替换为你的文件路径

library(dplyr)
library(ggplot2)
library(viridis)
position = position_dodge(width = 0.8)



dodge_value %>%
  ggplot(aes(y = measure, x = question_content, fill = condition)) +
  geom_violin(alpha = 0.5, position = position_dodge(width = 0.8)) +
  geom_boxplot(width = 0.2,
               alpha = 0.7,
               position = position_dodge(width = 0.8)) +
  stat_summary(fun = "mean",
               geom = "point",
               position = position_dodge(width = 0.8)) +
  stat_summary(fun.data = "mean_cl_boot",
               geom = "errorbar",
               width = .1,
               position = position_dodge(width = 0.8)) +
  scale_fill_viridis_d(option = "E") +
  scale_y_continuous(name = "Interest score (1-7)",
                     breaks = c(1:7)) +
  theme_classic()

#计算ANOVA
mod_factorial <- aov_ez(id = "user_id",
                        data = dodge_value, 
                        within = c( "question_content","condition"),
                    
                        dv = "measure", 
                        type = 3,
                        include_aov = TRUE,
                        anova_table = list(es = "pes"),
                        na.rm = TRUE) 

factorial_output <- mod_factorial$anova_table %>% 
  tidy()

mod_factorial
```

```{r}
# 看relationship和measure的相关性

df <- read_csv("all_data_srm_all.csv")
df %>% 
  ggplot(aes(x = relationship, y = measure)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  scale_x_continuous(name = "relationship", 
                     breaks = c(1:9)) + 
  scale_y_continuous(name = " measure", 
                     breaks = c(1:6))

library(correlation)
correlation(data = df, 
            select = "relationship", 
            select2 = "measure",  
            method = "spearman",
            alternative = "two.sided")


#按照问题分组
library(purrr)

# 1. 按 question_content 分组
grouped <- df %>%
  group_by(question_content) %>%
  group_split()

# 2. 对每一组运行 correlation()
cor_list <- map(grouped, ~ correlation(select(., relationship, measure), method = "spearman"))

# 3. 加上分组名并组合成一个表
names(cor_list) <- sapply(grouped, function(x) unique(x$question_content))
cor_combined <- bind_rows(cor_list, .id = "question_content")

# 查看
print(cor_combined)
```
```{r}
#合并新的表 all_data

library(tidyverse)

# 定义文件路径列表
file_paths <- c(
  "data/behavior/mkreal_meeting_experiment_prolific1.csv",
  "data/behavior/mkreal_meeting_experiment_prolific2.csv",
  "data/behavior/mkreal_meeting_experiment_prolific3.csv",
  "data/behavior/mkreal_meeting_experiment_prolific4.csv",
  "data/behavior/mkreal_meeting_experiment_prolific5.csv",
  "data/behavior/mkreal_meeting_experiment_prolific6.csv",
  "data/behavior/pilot_mkprolific_participant_real_21.csv",
  "data/behavior/pilot_mkprolific_participant_real_22.csv",
  "data/behavior/pilot_mkprolific_participant_real_31.csv",
  "data/behavior/pilot_mkprolific_participant_real_32.csv"
)

# 创建空列表存储处理后的数据
all_data_list <- list()

# 遍历所有文件路径
for (file_path in file_paths) {
  # 读取CSV文件
  df <- read_csv(file_path, show_col_types = FALSE)
  
  # 提取所需列名 - 使用单数形式匹配
  sid_col <- names(df)[str_detect(names(df), "session\\.config\\.id")]
  dyad_col <- names(df)[str_detect(names(df), "dyad$")]
  user_id_col <- names(df)[str_detect(names(df), "user_id$")]
  other_id_col <- names(df)[str_detect(names(df), "other_id$")]
  part_cond_col <- names(df)[str_detect(names(df), "participant_condition$")]
  other_cond_col <- names(df)[str_detect(names(df), "other_condition$")]
  
  # 检查是否找到必需的列
  if (length(sid_col) == 0 || 
      length(dyad_col) == 0 || 
      length(user_id_col) == 0 || 
      length(other_id_col) == 0 || 
      length(part_cond_col) == 0 || 
      length(other_cond_col) == 0) {
    message(paste("Skipping file due to missing columns:", file_path))
    next
  }
  
  # 提取问题列
  question_cols <- names(df)[str_detect(names(df), 
                                       "(liked$|other_liked$|conversation_quality$|video_conf_quality$)")]
  
  # 创建基础数据框
  base_df <- df %>%
    select(
      sid = all_of(sid_col),
      dyad = all_of(dyad_col),
      user_id_raw = all_of(user_id_col),
      other_id_raw = all_of(other_id_col),
      participant_condition = all_of(part_cond_col),
      other_condition = all_of(other_cond_col)
    ) %>%
    mutate(
      user_id = paste0(sid, "__", user_id_raw),
      other_id = paste0(sid, "__", other_id_raw)
    ) %>%
    select(-user_id_raw, -other_id_raw)
  
  # 转换问题列为长格式
  if (length(question_cols) > 0) {
    question_df <- df %>%
      select(all_of(question_cols)) %>%
      pivot_longer(
        cols = everything(),
        names_to = "question_content",
        values_to = "measure"
      )
    
    # 合并基础数据与问题数据
    expanded_df <- base_df[rep(seq_len(nrow(base_df)), each = length(question_cols)), ] %>%
      bind_cols(question_df)
    
    all_data_list[[file_path]] <- expanded_df
  } else {
    message(paste("No question columns found in:", file_path))
  }
}

# 合并所有表并添加索引
if (length(all_data_list) > 0) {
  all_data <- bind_rows(all_data_list) %>%
    mutate(Index = row_number()) %>%
    select(Index, sid, dyad, user_id, other_id, 
           participant_condition, other_condition, 
           question_content, measure)
  
  # 查看结果
  print(glimpse(all_data))
} else {
  stop("No data was processed. Check for missing columns in input files.")
}
# 保存
write_csv(all_data, "data/behavior/all_data.csv")



```

